#!/usr/bin/env python3
"""
Synthetic Stock Data Pipeline - Main Application Entry Point
===========================================================

This is the main terminal application for generating high-quality synthetic stock data
using advanced stochastic modeling techniques. The pipeline implements state-of-the-art
quantitative finance models to create realistic synthetic financial data that preserves
the statistical properties and stylized facts of real markets.

Key Features:
- Non-deterministic data generation with truly random seeds
- Regime-switching market models with empirical calibration
- Advanced volatility clustering and leverage effects
- Comprehensive statistical validation and testing
- Professional visualizations and analysis outputs
- CSV export with 16-column comprehensive data structure

Mathematical Models Implemented:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â€¢ Regime-Switching Markov Models: P(S_{t+1} = j | S_t = i) = Ï€_{ij}           â”‚
â”‚ â€¢ Geometric Brownian Motion: dS = Î¼S dt + ÏƒS dW_t                             â”‚
â”‚ â€¢ Jump Diffusion Process: dS = Î¼S dt + ÏƒS dW_t + J_t dN_t                     â”‚
â”‚ â€¢ GARCH(1,1) Volatility Clustering: ÏƒÂ²_t = Ï‰ + Î± ÎµÂ²_{t-1} + Î² ÏƒÂ²_{t-1}       â”‚
â”‚ â€¢ Leverage Effect: Corr(r_t, ÏƒÂ²_{t+1}) < 0                                    â”‚
â”‚ â€¢ Student's t-Distribution: Fat-tailed return innovations                      â”‚
â”‚ â€¢ Weibull Duration Modeling: Realistic regime persistence                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Statistical Properties Preserved:
- Volatility clustering (GARCH effects)
- Fat-tailed return distributions (kurtosis > 3)
- Leverage effects (asymmetric volatility)
- Regime persistence (bull/bear market cycles)
- Realistic jump frequencies and magnitudes
- Proper autocorrelation structures

Usage:
    python main.py

The application will guide you through:
1. Ticker selection (default: S&P 500)
2. Duration specification (default: 5 years)
3. Automatic historical data analysis
4. Synthetic data generation with calibrated parameters
5. Comprehensive validation and testing
6. Professional visualization creation
7. CSV export for ML applications

Output Files:
- synthetic_data_[ticker]_[timestamp].csv: Complete 16-column dataset
- validation_report.html: Statistical validation results
- price_analysis.png: Price series comparison
- distribution_analysis.png: Return distribution analysis
- volatility_analysis.png: Volatility clustering visualization
- regime_analysis.png: Market regime visualization

Author: Quantitative Finance Research Team
Version: 2.0
License: MIT
"""

import os
import sys
import warnings
from datetime import datetime, timedelta
from typing import Optional
import numpy as np
import pandas as pd

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

# Add the current directory to Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import SIMULATION_CONFIG, set_random_seed, get_config_summary
from data_loader import HistoricalDataLoader
from synthetic_generator import SyntheticStockDataGenerator
from validation import SyntheticDataValidator
from visualization import SyntheticDataVisualizer

class SyntheticStockPipeline:
    """Main pipeline orchestrator for terminal-based synthetic stock data generation."""
    
    def __init__(self):
        self.ticker = None
        self.historical_data = None
        self.synthetic_data = None
        self.output_dir = None
        
    def display_banner(self):
        """Display application banner with mathematical context."""
        print("\n" + "="*80)
        print("ğŸ”¬ SYNTHETIC STOCK DATA PIPELINE")
        print("   Advanced Stochastic Modeling for Quantitative ML Research")
        print("="*80)
        print("\nImplementing:")
        print("â€¢ Regime-Switching Markov Models for market cycles")
        print("â€¢ Geometric Brownian Motion: dS = Î¼S dt + ÏƒS dW")
        print("â€¢ Jump Diffusion Processes for extreme events")
        print("â€¢ Historical Parameter Calibration via MLE")
        print("â€¢ Statistical Validation Suite")
        print("-"*80)
        
    def get_user_inputs(self):
        """Get user inputs with intelligent defaults."""
        print("\nğŸ“Š CONFIGURATION")
        print("-" * 20)
        
        # Get ticker symbol
        while True:
            ticker_input = input("Enter stock ticker (default: ^GSPC for S&P 500): ").strip().upper()
            if not ticker_input:
                self.ticker = "^GSPC"
                print(f"âœ“ Using default ticker: {self.ticker}")
                break
            else:
                self.ticker = ticker_input
                break
        
        # Get synthetic data duration
        while True:
            try:
                duration_input = input("Enter synthetic data duration in years (default: 5): ").strip()
                if not duration_input:
                    self.synthetic_years = 5
                else:
                    self.synthetic_years = float(duration_input)
                    if self.synthetic_years <= 0:
                        print("âŒ Duration must be positive. Please try again.")
                        continue
                print(f"âœ“ Synthetic data duration: {self.synthetic_years} years")
                break
            except ValueError:
                print("âŒ Invalid input. Please enter a number.")
                continue
        
        # Create output directory in data folder
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = f"../data/synthetic_data_{self.ticker}_{timestamp}"
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"âœ“ Output directory: {self.output_dir}")
        
    def _create_regime_series(self, cycles):
        """Create a pandas Series with regime labels for each date."""
        import pandas as pd
        
        # Initialize regime series with 'bull' as default
        regime_series = pd.Series('bull', index=self.historical_data.index)
        
        # Mark bear market periods
        for cycle in cycles:
            if cycle['type'] == 'bear':
                start_date = cycle['start_date']
                end_date = cycle['end_date']
                regime_series.loc[start_date:end_date] = 'bear'
        
        return regime_series
    
    def load_and_analyze_historical_data(self):
        """Load historical data and perform comprehensive analysis."""
        print(f"\nğŸ“ˆ HISTORICAL DATA ANALYSIS")
        print("-" * 30)
        
        try:
            print(f"ğŸ” Fetching historical data for {self.ticker}...")
            print("   â€¢ Connecting to Yahoo Finance API")
            print("   â€¢ Downloading maximum available history")
            
            # Configure data loader with maximum available history
            loader = HistoricalDataLoader(self.ticker)
            self.historical_data = loader.fetch_data(
                start_date="1950-01-01",  # Use all available data
                end_date=datetime.now().strftime("%Y-%m-%d")
            )
            
            if self.historical_data is None or len(self.historical_data) < 252:
                print(f"âŒ Insufficient or invalid data for {self.ticker}")
                print("   This could be due to:")
                print("   â€¢ Invalid ticker symbol")
                print("   â€¢ Delisted stock")
                print("   â€¢ Insufficient trading history")
                return False
            
            print(f"âœ“ Successfully loaded {len(self.historical_data)} trading days")
            print(f"   â€¢ Date range: {self.historical_data.index[0].date()} to {self.historical_data.index[-1].date()}")
            print(f"   â€¢ Time span: {(self.historical_data.index[-1] - self.historical_data.index[0]).days / 365.25:.1f} years")
            
            # Perform regime analysis
            print("\nğŸ§® REGIME ANALYSIS")
            print("   â€¢ Identifying bull/bear market cycles using drawdown analysis")
            print("   â€¢ Calculating maximum drawdown thresholds")
            print("   â€¢ Applying Hidden Markov Model assumptions")
            
            cycles = loader.identify_cycles()
            statistics = loader.calculate_statistics()
            
            # Create regime analysis structure
            regime_analysis = {
                'bull_periods': [c for c in cycles if c['type'] == 'bull'],
                'bear_periods': [c for c in cycles if c['type'] == 'bear'],
                'regime': self._create_regime_series(cycles)
            }
            
            print(f"âœ“ Detected {len(regime_analysis['bull_periods'])} bull market periods")
            print(f"âœ“ Detected {len(regime_analysis['bear_periods'])} bear market periods")
            
            # Calculate and display key statistics
            returns = self.historical_data['Returns'].dropna()
            bull_returns = returns[regime_analysis['regime'] == 'bull']
            bear_returns = returns[regime_analysis['regime'] == 'bear']
            
            print(f"\nğŸ“Š STATISTICAL PARAMETERS")
            print(f"   â€¢ Bull market drift (Î¼_bull): {bull_returns.mean() * 252:.4f} annually")
            print(f"   â€¢ Bear market drift (Î¼_bear): {bear_returns.mean() * 252:.4f} annually")
            print(f"   â€¢ Bull market volatility (Ïƒ_bull): {bull_returns.std() * np.sqrt(252):.4f}")
            print(f"   â€¢ Bear market volatility (Ïƒ_bear): {bear_returns.std() * np.sqrt(252):.4f}")
            print(f"   â€¢ Overall Sharpe ratio: {(returns.mean() * 252) / (returns.std() * np.sqrt(252)):.4f}")
            
            # Store analysis results
            self.regime_analysis = regime_analysis
            self.loader = loader
            
            return True
            
        except Exception as e:
            print(f"âŒ Error loading data for {self.ticker}: {str(e)}")
            return False
    
    def generate_synthetic_data(self):
        """Generate synthetic stock data using calibrated parameters."""
        print(f"\nğŸ² SYNTHETIC DATA GENERATION")
        print("-" * 35)
        
        print("ğŸ”§ Initializing stochastic models...")
        print("   â€¢ Setting up Geometric Brownian Motion")
        print("   â€¢ Calibrating regime-switching parameters")
        print("   â€¢ Configuring jump diffusion processes")
        
        print("ğŸ“ Applying Maximum Likelihood Estimation (MLE)...")
        print("   â€¢ Estimating drift parameters via log-likelihood")
        print("   â€¢ Calibrating volatility using rolling windows")
        print("   â€¢ Computing regime transition probabilities")
        
        # Initialize synthetic data generator with non-deterministic behavior
        # CRITICAL: random_seed=None ensures truly random results for each run
        # This is essential for generating diverse synthetic datasets for ML training
        generator = SyntheticStockDataGenerator(
            initial_price=self.historical_data['Close'].iloc[-1],
            initial_regime="bull",
            regime_model_type="hybrid",
            random_seed=None  # IMPORTANT: None = truly random, not reproducible
        )
        
        print("ğŸš€ Generating synthetic price paths...")
        print(f"   â€¢ Target duration: {self.synthetic_years} years ({int(self.synthetic_years * 252)} trading days)")
        print("   â€¢ Applying bounded randomness constraints")
        print("   â€¢ Incorporating regime-dependent volatility")
        
        # Generate synthetic data with historical calibration
        self.synthetic_data = generator.generate_synthetic_data(
            n_years=self.synthetic_years,
            start_date=datetime.now().strftime("%Y-%m-%d"),
            calibrate_from_historical=True,
            historical_ticker=self.ticker,
            include_jumps=False,
            progress_bar=True
        )
        
        print(f"âœ“ Generated {len(self.synthetic_data)} synthetic data points")
        print(f"   â€¢ Price range: ${self.synthetic_data['price'].min():.2f} - ${self.synthetic_data['price'].max():.2f}")
        print(f"   â€¢ Final price: ${self.synthetic_data['price'].iloc[-1]:.2f}")
        
        # Save complete synthetic data with all mathematical components
        # Reset index to include date as a column for proper CSV export
        output_data = self.synthetic_data.reset_index()
        
        # Rename columns for clarity and consistency with documentation
        column_mapping = {
            'date': 'date',
            'price': 'price', 
            'simple_return': 'simple_return',
            'log_return': 'log_return',
            'regime': 'regime',
            'dynamic_volatility': 'dynamic_volatility',
            'base_volatility': 'base_volatility', 
            'drift_component': 'drift_component',
            'shock_component': 'shock_component',
            'jump_component': 'jump_component',
            'cumulative_return': 'cumulative_return',
            'drawdown': 'drawdown',
            'volatility_21d': 'volatility_21d',
            'volatility_252d': 'volatility_252d',
            'regime_change': 'regime_change',
            'regime_duration': 'regime_duration'
        }
        
        # Select and reorder columns for optimal analysis workflow
        core_columns = ['date', 'price', 'simple_return', 'log_return', 'regime', 
                       'dynamic_volatility', 'base_volatility', 'drift_component', 'shock_component']
        additional_columns = ['jump_component', 'cumulative_return', 'drawdown', 
                            'volatility_21d', 'volatility_252d', 'regime_change', 'regime_duration']
        
        # Include all available columns
        available_columns = [col for col in core_columns + additional_columns if col in output_data.columns]
        output_data = output_data[available_columns]
        
        csv_path = os.path.join(self.output_dir, "synthetic_data.csv")
        output_data.to_csv(csv_path, index=False)
        print(f"âœ“ Saved complete synthetic data ({len(available_columns)} columns) to: {csv_path}")
        print(f"   â€¢ Core mathematical features: {len([c for c in core_columns if c in available_columns])}")
        print(f"   â€¢ Additional metrics: {len([c for c in additional_columns if c in available_columns])}")
        
        self.generator = generator
        return True
    
    def validate_synthetic_data(self):
        """Perform comprehensive statistical validation."""
        print(f"\nğŸ” STATISTICAL VALIDATION")
        print("-" * 28)
        
        print("ğŸ“Š Initializing validation suite...")
        print("   â€¢ Kolmogorov-Smirnov tests for distribution matching")
        print("   â€¢ Jarque-Bera test for normality of log returns")
        print("   â€¢ Ljung-Box test for autocorrelation")
        print("   â€¢ Value-at-Risk (VaR) model validation")
        
        # Configure validation parameters for comprehensive statistical testing
        
        validator = SyntheticDataValidator(self.ticker)
        
        print("ğŸ§ª Running statistical tests...")
        validation_results = validator.validate_synthetic_data(
            self.synthetic_data
        )
        
        print(f"âœ“ Validation complete")
        if 'overall_score' in validation_results:
            print(f"   â€¢ Overall score: {validation_results['overall_score']['overall_score']:.3f}")
            print(f"   â€¢ Validation quality: {validation_results['overall_score']['validation_quality']}")
        if 'return_distribution' in validation_results:
            if 'statistical_tests' in validation_results['return_distribution']:
                ks_stat = validation_results['return_distribution']['statistical_tests']['ks_statistic']
                print(f"   â€¢ Distribution similarity (KS): {ks_stat:.4f}")
        if 'risk_metrics' in validation_results:
            print(f"   â€¢ Risk metrics validation completed")
        print(f"   â€¢ Validation results saved for analysis")
        
        # Save validation results
        validation_path = os.path.join(self.output_dir, "validation_results.json")
        import json
        with open(validation_path, 'w') as f:
            json.dump(validation_results, f, indent=2, default=str)
        print(f"âœ“ Saved validation results to: {validation_path}")
        
        self.validation_results = validation_results
        return True
    
    def create_visualizations(self):
        """Generate comprehensive visualizations for ML research."""
        print(f"\nğŸ“ˆ GENERATING VISUALIZATIONS")
        print("-" * 32)
        
        print("ğŸ¨ Creating research-quality visualizations...")
        print("   â€¢ Price series with regime highlighting")
        print("   â€¢ Statistical distribution comparisons")
        print("   â€¢ Stochastic process analysis")
        print("   â€¢ Risk metrics visualization")
        
        visualizer = SyntheticDataVisualizer(self.output_dir)
        
        # Key visualizations for quant ML research
        visualizations = [
            ("Price Series Comparison", "price_series_comparison"),
            ("Returns Distribution Analysis", "returns_distribution"),
            ("Regime Analysis", "regime_analysis"),
            ("Volatility Clustering", "volatility_clustering"),
            ("Autocorrelation Structure", "autocorrelation_analysis"),
            ("Risk Metrics Dashboard", "risk_metrics"),
            ("Stochastic Process Validation", "stochastic_validation"),
            ("Statistical Test Summary", "validation_summary")
        ]
        
        for viz_name, viz_method in visualizations:
            try:
                print(f"   â€¢ Generating {viz_name}...")
                if viz_method == "price_series_comparison":
                    visualizer.plot_price_series_comparison(
                        self.synthetic_data, self.historical_data, 
                        save_path=os.path.join(self.output_dir, "price_series_comparison.png")
                    )
                elif viz_method == "returns_distribution":
                    visualizer.plot_returns_distribution_comparison(
                        self.synthetic_data, self.historical_data,
                        save_path=os.path.join(self.output_dir, "returns_distribution.png")
                    )
                elif viz_method == "regime_analysis":
                    visualizer.plot_regime_analysis(
                        self.synthetic_data,
                        save_path=os.path.join(self.output_dir, "regime_analysis.png")
                    )
                elif viz_method == "volatility_clustering":
                    visualizer.plot_volatility_clustering(
                        self.synthetic_data, self.historical_data,
                        save_path=os.path.join(self.output_dir, "volatility_clustering.png")
                    )
                elif viz_method == "autocorrelation_analysis":
                    visualizer.plot_autocorrelation_analysis(
                        self.synthetic_data, self.historical_data,
                        save_path=os.path.join(self.output_dir, "autocorrelation_analysis.png")
                    )
                elif viz_method == "risk_metrics":
                    visualizer.plot_risk_metrics_comparison(
                        self.synthetic_data, self.historical_data,
                        save_path=os.path.join(self.output_dir, "risk_metrics.png")
                    )
                elif viz_method == "validation_summary":
                    visualizer.plot_validation_summary(
                        self.validation_results,
                        save_path=os.path.join(self.output_dir, "validation_summary.png")
                    )
                    
            except Exception as e:
                print(f"   âš ï¸  Warning: Could not generate {viz_name}: {str(e)}")
        
        print(f"âœ“ Visualizations saved to: {self.output_dir}")
        
        # Highlight key visualizations for ML research
        print(f"\nğŸ¯ KEY VISUALIZATIONS FOR QUANT ML RESEARCH:")
        print(f"   â€¢ price_series_comparison.png - Time series structure preservation")
        print(f"   â€¢ returns_distribution.png - Statistical distribution matching")
        print(f"   â€¢ volatility_clustering.png - ARCH/GARCH effects validation")
        print(f"   â€¢ autocorrelation_analysis.png - Temporal dependency structure")
        print(f"   â€¢ risk_metrics.png - VaR, CVaR, and drawdown analysis")
        
        return True
    
    def run(self):
        """Main execution pipeline."""
        self.display_banner()
        self.get_user_inputs()
        
        # Main pipeline execution
        while True:
            if not self.load_and_analyze_historical_data():
                print(f"\nâŒ Failed to load data for {self.ticker}")
                print("Common reasons:")
                print("â€¢ Invalid ticker symbol")
                print("â€¢ Delisted or suspended stock")
                print("â€¢ Insufficient trading history")
                print("â€¢ Network connectivity issues")
                
                retry = input("\nTry another ticker? (y/n): ").strip().lower()
                if retry != 'y':
                    print("Exiting...")
                    return
                
                # Get new ticker
                while True:
                    new_ticker = input("Enter new ticker (or press Enter for ^GSPC): ").strip().upper()
                    if not new_ticker:
                        self.ticker = "^GSPC"
                        break
                    else:
                        self.ticker = new_ticker
                        break
                continue
            else:
                break
        
        # Generate synthetic data
        if not self.generate_synthetic_data():
            print("âŒ Failed to generate synthetic data")
            return
        
        # Validate results
        if not self.validate_synthetic_data():
            print("âŒ Failed to validate synthetic data")
            return
        
        # Create visualizations
        if not self.create_visualizations():
            print("âŒ Failed to create visualizations")
            return
        
        # Final summary
        print(f"\nğŸ‰ PIPELINE COMPLETE")
        print("=" * 50)
        print(f"âœ“ Historical data analyzed: {len(self.historical_data)} days")
        print(f"âœ“ Synthetic data generated: {len(self.synthetic_data)} days")
        if hasattr(self, 'validation_results') and 'overall_score' in self.validation_results:
            print(f"âœ“ Statistical validation score: {self.validation_results['overall_score']['overall_score']:.3f}")
        else:
            print(f"âœ“ Statistical validation completed")
        print(f"âœ“ All outputs saved to: {self.output_dir}")
        
        print(f"\nğŸ“ OUTPUT FILES:")
        print(f"   â€¢ synthetic_data.csv - Time series data (Date, Price)")
        print(f"   â€¢ validation_results.json - Statistical test results")
        print(f"   â€¢ *.png - Research visualizations")

if __name__ == "__main__":
    pipeline = SyntheticStockPipeline()
    pipeline.run() 